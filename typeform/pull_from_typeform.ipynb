{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and preparation\n",
    "\n",
    "- place this notebook in ../typeform \n",
    "- store your own token for tf API in a file called \"typeform_token.py\" and save it locally (do not commit) in /typeform\n",
    "- The file contains only one line: TOKEN=\"your_token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import textwrap\n",
    "\n",
    "#import my own function\n",
    "%run one_entry_to_dictionary.py\n",
    "%run typeform_token.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pull Data from Typeform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to TF, see metainfo for form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT TOKEN FILE \n",
    "auth_token= TOKEN\n",
    "head = {'Authorization': 'Bearer ' + auth_token}\n",
    "url = 'https://api.typeform.com/forms/OHziDn'\n",
    "\n",
    "metainfo_form = requests.get(url, headers=head)\n",
    "#response 200 means its good !\n",
    "print(metainfo_form)\n",
    "print(metainfo_form.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull all responses exclusing mail from Typeform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all answers but not emails\n",
    "SIZE = \"500\"\n",
    "url = \"https://api.typeform.com/forms/OHziDn/responses?fields=Xa2T0bcZ5VnY,QUtA6k0gcrZf,ZNZyNVwMtwID,azlKRkvdcc7O,Vrzj2uv0i29C,Xh2W1d6FhXyK,t9EaTsONnJfR,OaujoVSY6NaS,ASolp4v3adZK,erHBE6gKxycf,ASQmq4h3vxRt,KEGztC8iYfyy,kWb7LUjdJyhb,g9goY6hIxmC9,jG2wzvAmOWxq,HNqA7BK7ZDFl&page_size=\"+SIZE\n",
    "\n",
    "response = requests.get(url, headers=head)\n",
    "#response 200 means its good !\n",
    "print(response)\n",
    "\n",
    "responses = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of responses\",responses['total_items'])\n",
    "#look at the first response\n",
    "print(\"the last response:\",responses[\"items\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transform JSON to pandas.df and map dummy vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ONE PERSON FROM THE JSON RESPONSE\n",
    "one_person = responses[\"items\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform ONE person's information to a dictionary using function one_entry_to_dictionary\n",
    "dictionary_test = one_entry_to_dictionary(one_person)\n",
    "print(dictionary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary to df \n",
    "df_test = pd.DataFrame(dictionary_test,index=[0])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply this to entire JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_all_to_df(responses):\n",
    "    '''\n",
    "    transforms the JSON response from the above query into a df with cols=vars, rows=individuals\n",
    "    '''\n",
    "    no_df_defined = True\n",
    "    for item in responses[\"items\"]:\n",
    "        dictionary_transformation = one_entry_to_dictionary(item)\n",
    "        df = pd.DataFrame(dictionary_transformation,index=[0])\n",
    "        #crate dictionary and then append to it \n",
    "        if no_df_defined:\n",
    "            df_all = df\n",
    "            no_df_defined = False\n",
    "        else: \n",
    "            df_all = df_all.append(df)\n",
    "        df_all = df_all.reset_index(drop = True)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = transform_all_to_df(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to save the data \n",
    "\"\"\"\n",
    "timestr = time.strftime(\"%Y%m%d%H%M\")\n",
    "file_name = \"survey_data_\" + timestr\n",
    "print(file_name)\n",
    "\n",
    "df_all.to_csv(\"../data/\" + file_name + \".csv\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation for Graph 0 - Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from overview_tab.map_graph import merge_local_internat_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_code = pd.read_csv(\"../data/postcode_uk.csv\", index_col = 0)\n",
    "#countries = pd.read_csv(\"https://raw.githubusercontent.com/rjcnrd/domestic_violence_covid-19/master/data/countries.csv\")\n",
    "countries = pd.read_csv(\"../data/countries.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reports_df, safety_df, safety_change_df, mental_health_df, working_situation_df, not_in_map, uk_data, uk_data_county = merge_local_internat_dataframe(survey_df = df_all, postal_code_df = postal_code, countries_df = countries,  map_threshold = 0, postal_code_col = \"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reports_df.to_csv(\"../data/data_map_all_reports.csv\")\n",
    "safety_df.to_csv(\"../data/data_map_safety_scale.csv\")\n",
    "safety_change_df.to_csv(\"../data/data_map_safety_change.csv\")\n",
    "mental_health_df.to_csv(\"../data/data_map_mental_health.csv\")\n",
    "working_situation_df.to_csv(\"../data/data_map_working_situation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for the rows that are not integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are the values that are not integrated, by order\n",
    "not_in_map.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to append new location, you should update the countries csv, one by one \n",
    "#country_name : name of the country as you see it in the survey\n",
    "#Area : name of the country as it appears already in the survey. THIS WILL BE USED FOR A MERGE\n",
    "#Area_name : name of the country as it should appear in the hover (the same name as area name)\n",
    "\"\"\"\n",
    "countries_new = countries.append({\"latitude\": 22.396428, \n",
    "                                  \"longitude\": 114.10949699999999, \n",
    "                                  \"country_name\" : \"HKSAR\",\n",
    "                                  \"area\": \"HONG KONG\", \n",
    "                                  \"area_name\": \"Hong Kong\"}, ignore_index=True)\n",
    "countries_new.to_csv(\"/Users/ameliemeurer/Documents/Am√©lie/HEC M2/07. Research Paper - UN Women/02. Code/domestic_violence_covid-19/data/countries.csv\")\n",
    "                                  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Aggregation for Graph 1. Scatter-Testimonial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from statistics_tab.scatter_bar_plot_mental_health import location_scatterplot, merge_testimonials, testimonial_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the location for all the dots\n",
    "location_data = location_scatterplot(df_all, do_percentage = False, include_other=False, include_man = True, num_by_col=5)\n",
    "location_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the treatment for testimonials \n",
    "MAXIMUM_TOTAL_LENGTH = 150 #Maximum length of testimonial\n",
    "MAXIMUM_LINE_LENGTH = 30 #Maximum length of the line on hover\n",
    "MINIMUM_TOTAL_LENGTH = 10 #Minimum length of testimonial\n",
    "testimonial_treated = testimonial_treatment(df_all[[\"gender\", \"mental_scale\",\"testimonial\"]], \n",
    "                                            maximum_total_length = MAXIMUM_TOTAL_LENGTH, \n",
    "                                            maximum_line_length = MAXIMUM_LINE_LENGTH, \n",
    "                                            minimum_total_length = MINIMUM_TOTAL_LENGTH)\n",
    "testimonial_treated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merges the 2 dataframes\n",
    "data_scatterplot = merge_testimonials(location_data, testimonial_treated, include_other = False)\n",
    "data_scatterplot.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scatterplot.to_csv(\"data_scatterplot.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
